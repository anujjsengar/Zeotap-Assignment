{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ewMHLQbyAutF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "customers_df = pd.read_csv(\"Customers.csv\")\n",
        "products_df = pd.read_csv(\"Products.csv\")\n",
        "transactions_df = pd.read_csv(\"Transactions.csv\")\n",
        "\n",
        "# merge all datasets\n",
        "transactions_df = transactions_df.merge(products_df, on=\"ProductID\")\n",
        "merged_df = transactions_df.merge(customers_df, on=\"CustomerID\")\n",
        "\n",
        "# Viewing data\n",
        "print(merged_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on8wgZmSBAkb",
        "outputId": "ad621a51-787b-486c-fd2f-cf12c107e456"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
            "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
            "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
            "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
            "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
            "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
            "\n",
            "   TotalValue  Price_x                      ProductName     Category  Price_y  \\\n",
            "0      300.68   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
            "1      300.68   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
            "2      300.68   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
            "3      601.36   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
            "4      902.04   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
            "\n",
            "      CustomerName         Region  SignupDate  \n",
            "0   Andrea Jenkins         Europe  2022-12-03  \n",
            "1  Brittany Harvey           Asia  2024-09-04  \n",
            "2  Kathryn Stevens         Europe  2024-04-04  \n",
            "3  Travis Campbell  South America  2024-04-11  \n",
            "4    Timothy Perez         Europe  2022-03-15  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize transaction data per customer\n",
        "transaction_summary = merged_df.groupby('CustomerID').agg({\n",
        "    'TotalValue': ['sum', 'mean'],       # Total and average spending\n",
        "    'TransactionID': 'count',           # Number of transactions\n",
        "    'Category': lambda x: x.mode()[0]   # Most purchased category\n",
        "}).reset_index()\n",
        "\n",
        "# Flatten multi-level column names\n",
        "transaction_summary.columns = ['CustomerID', 'TotalSpending', 'AvgSpending', 'TransactionCount', 'FavCategory']\n",
        "\n",
        "# Merge with customer profiles\n",
        "customer_profiles = customers_df.merge(transaction_summary, on='CustomerID')\n",
        "\n",
        "# One-hot encode categorical features (Region and FavCategory)\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "encoded_region = encoder.fit_transform(customer_profiles[['Region']])\n",
        "encoded_category = encoder.fit_transform(customer_profiles[['FavCategory']])\n",
        "\n",
        "print(customer_profiles.columns)\n",
        "\n",
        "features = np.hstack([\n",
        "    encoded_region,\n",
        "    encoded_category,\n",
        "    customer_profiles[['TotalSpending', 'AvgSpending', 'TransactionCount']].values\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# Standardize features using standard scaler\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDKs8S61BDG4",
        "outputId": "613001b7-0999-446d-b262-d30e7503f498"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['CustomerID', 'CustomerName', 'Region', 'SignupDate', 'TotalSpending',\n",
            "       'AvgSpending', 'TransactionCount', 'FavCategory'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute cosine similarity matrix(mathematcial formula for cosine similarity: the dot product divided by the product of the two vectors' magnitudes)\n",
        "similarity_matrix = cosine_similarity(features_scaled)\n",
        "\n",
        "# extracting Customer IDs\n",
        "customer_ids = customer_profiles['CustomerID'].values\n",
        "\n",
        "# as per task generating top-3 lookalikes for the first 20 customers\n",
        "lookalikes = {}\n",
        "\n",
        "for i, customer_id in enumerate(customer_ids[:20]):  # First 20 customers\n",
        "    similarities = list(enumerate(similarity_matrix[i]))\n",
        "    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)  # Sort by similarity score\n",
        "    top_3 = [(customer_ids[j], score) for j, score in similarities[1:4]]  # Exclude self, pick top 3\n",
        "    lookalikes[customer_id] = top_3\n",
        "\n",
        "# Convert to dataframe for output in csv\n",
        "lookalike_list = []\n",
        "for cust_id, similar in lookalikes.items():\n",
        "    for sim_cust_id, score in similar:\n",
        "        lookalike_list.append({'CustomerID': cust_id, 'SimilarCustomerID': sim_cust_id, 'Score': score})\n",
        "\n",
        "lookalike_df = pd.DataFrame(lookalike_list)\n",
        "lookalike_df.to_csv(\"Lookalike.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "phUe2aSEBMqB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5NhZc7aoEU5k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}